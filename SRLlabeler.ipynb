{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00a1644c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 14:53:29.613919: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-14 14:53:29.613933: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "lerc is not a registered model.\n",
      "visual-entailment is not a registered model.\n",
      "vqa_vilbert is not a registered model.\n"
     ]
    }
   ],
   "source": [
    "from allennlp_models import pretrained\n",
    "import re\n",
    "allenslr=pretrained.load_predictor('structured-prediction-srl-bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583ca68b",
   "metadata": {},
   "source": [
    "# Improvements in labeler algorithm from the study of the PropBank anotation rules "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffd794a",
   "metadata": {},
   "source": [
    "#### ¿Qué es PropBank?\n",
    "- Es un cuerpo anotado con proposiciones verbales y sus argumentos\n",
    "- Es un recurso orientado a verbos\n",
    "- PropBank no anota enventos o estados de las cosas descritas usando sustantivos\n",
    "- PropBank anota todos los verbos encontrados en un corpus\n",
    "\n",
    "**Necesita que todos los argumentos de un verbo sean constituyentes sintácticos y los diferentes sentidos de una palabra solo se distinguen si las diferencias se relacionan con los argumentos**\n",
    "\n",
    "#### ¿Qué son los argumentos de un verbo?\n",
    "Entendermos los argumentos como las _palabras necesarias_ para un correcto entendimiento (gramatical) de las frases. \n",
    "\n",
    "#### ¿Qué son los constituyentes sintácticos?\n",
    "Son una palabra o conjunto de palabras que funcionan como una sola unidad dentro de una estructura jerárquica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406e41ec-211c-47f0-a0ff-7c187e76cefe",
   "metadata": {},
   "source": [
    "## Working with AllenNLP\n",
    "AllenNLP identificará cada uno de los verbos (y modales) presentes en la oración y para cada uno de ellos intentará clasificar las demás palabras en la oración si las reconoce como argumentos válidos. Esto supone un primer problema a la hora de utilizar la herramienta, pues la salida del predictor dada una oración tendrá identificaciones correctas e incorrectas de verbos y argumentos. Por ejemplo, de la oración\n",
    "\n",
    "_If you liked the music we were playing last night, you will absolutely love what we're playing tomorrow!_\n",
    "\n",
    "El modelo distinguirá un total de cinco verbos\n",
    "- liked\n",
    "- were\n",
    "- playing\n",
    "- will\n",
    "- love\n",
    "- are\n",
    "- playing\n",
    "\n",
    "Para cada uno de los verbos, AllenNLP buscará los argumentos verbales y procederá a anotarlos.\n",
    "\n",
    "Dada la oración y la lista anterior de verbos, podemos augurar que las peores anotaciones se darán cuando AllenNLP intente anotar los argumentos para _were_, _will_ y _are_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd8d377",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=\"If you liked the music we were playing last night, you will absolutely love what we're playing tomorrow!\"\n",
    "output=allenslr.predict(sentence)\n",
    "print(\"\")\n",
    "print(\"verb: were\")\n",
    "print(output['verbs'][1]['description'])\n",
    "print(\"verb: will\")\n",
    "print(output['verbs'][3]['description'])\n",
    "print(\"verb: are\")\n",
    "print(output['verbs'][5]['description'])\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd4df66-6fbc-4c45-bce7-3cf2043973a2",
   "metadata": {},
   "source": [
    "En estos casos, el etiquetador fue incapaz de ir más allá de un reconocimiento incorrecto de los verbos.\n",
    "Veamos que las anotaciones mejoran cuando reconocemos correctamente los verbos y no los modales o auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d96a2d-ca73-4061-90a1-45d472262f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"liked\")\n",
    "print(output['verbs'][0]['description'])\n",
    "print(\"playing\")\n",
    "print(output['verbs'][2]['description'])\n",
    "print(\"love\")\n",
    "print(output['verbs'][4]['description'])\n",
    "print(\"playing\")\n",
    "print(output['verbs'][6]['description'])\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e286d163-f7e8-4ad6-8e61-e87463f3c868",
   "metadata": {},
   "source": [
    "En este caso el etiquetador realiza  anotaciones, distinguiendo los distintos tipos de argumentos\n",
    "- ARG0\n",
    "- ARG1\n",
    "- ARG2...\n",
    "- ARGM-\n",
    "\n",
    "## Etiquetado\n",
    "\n",
    "De acuerdo con las reglas de PropBank, las etiquetas de los argumentos dependen de los roles semánticos posibles, estas son etiquetadas como ARG0, ARG1, ARG2,... El prefijo ARGM- se refiere a modificadores del verbo temporales, de locación, de modo y demás.\n",
    "\n",
    "Por ejemplo, para el verbo play se etiqueta como `ARG0` al sujeto que toca \"we\", y como `ARG1` al objeto tocado \"the music\". Finalmente como modificador temporal el conjunto \"last night\". Notemos que bajo esta elección varias partes de la oración quedan sin ser anotadas. De acuerdo a las reglas de PropBank, éstas son las que no se consideran argumentos del verbo anotado.\n",
    "\n",
    "Otro ejemplo de esta misma situación se da cuando se vuelve a etiquetar como verbo \"playing\" pero ahora se reconoce como `ARG1` a la palabra \"what\" (lo que tocaremos mañana)\n",
    "\n",
    "De esta forma además del problema de la distinción correcta entre verbos, modales y auxiliares, está el problema de mutilación o pérdida de información por el etiquetado, que depende de los roles semánticos y argumentos válidos para el verbo seleccionado.\n",
    "\n",
    "En AllenNLP, aquellas palabras que no hayan podido ser anotadas se quedan con el tag 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fd6ce8-9f7e-4ab4-a9af-75f0ad11ff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['verbs'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d811e71b-9005-4f31-b3dd-181c38a907c3",
   "metadata": {},
   "source": [
    "## FrameSets\n",
    "\n",
    "Para algunos verbos, existen distintas interpretaciones (FrameSets) que se pueden dar en oraciones, dando lugar a distintos roles semánticos posibles. Por ejemplo con el verbo \"leave\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c6926a-55cf-4156-aa1e-b8020392cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=\"Mary left the room\"\n",
    "output=allenslr.predict(sentence)\n",
    "print(\"\")\n",
    "print(output['verbs'][0]['description'])\n",
    "print(\"ARG0 sujeto que se va\")\n",
    "print(\"ARG1 objeto dejado\")\n",
    "print(\"\")\n",
    "sentence=\"Mary left her daughter-in-law her pearls in her will\"\n",
    "output=allenslr.predict(sentence)\n",
    "print(output['verbs'][0]['description'])\n",
    "print(\"ARG0 sujeto que da\")\n",
    "print(\"ARG1 objeto dado\")\n",
    "print(\"ARG2 beneficiario\")\n",
    "print(\"ARGM modo\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a7bee1-13ce-4341-a101-3f1face7ad97",
   "metadata": {},
   "source": [
    "En ambos casos después de identificar el verbo, AllenNLP es capaz de distinguir los distintos FrameSets y realizar las anotaciones correctas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbd519c-5ecc-489f-bfc2-22fad62fc4fe",
   "metadata": {},
   "source": [
    "Otras formas en como se pueden tener distintos FrameSets de distintos verbos es agregando una partícula, modificándose los roles semánticos. Por ejemplo tomando el verbo \"keep\" a \"keep up\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc496d82-a609-456b-93f7-2c3159fa5855",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=\"John can't keep up with Mary's rapid mood swings.\"\n",
    "output=allenslr.predict(sentence)\n",
    "output['verbs'][1]['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1122d5bf-a853-4f34-951f-3178097a0fde",
   "metadata": {},
   "source": [
    "AllenNLP puede reconocer correctamente los argumentos excepto a la partícula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ee4ced-4d99-4e2f-a0ab-5fbefe6f40e9",
   "metadata": {},
   "source": [
    "## Elecciones de argumentos\n",
    "\n",
    "- ARG0 es asignado a argumentos que se entienden como agentes causantes o experimentadores\n",
    "- ARG1 es asaignado al paciente, el objeto que cambia de estado o está siendo afectado por la acción\n",
    "\n",
    "Dependiendo de los verbos y los roles, distintos objetos pueden clasificarse como distintos argumentos verbales. (objetos que pueden ser tomados en la misma oración tanto como objetos como pacientes). La regla de etiquetado señala que siempre debe ser etiquetado el de más alto rango. ARG0 > ARG1 > ARG2 ...\n",
    "\n",
    "En resumen, ARG0 son los argumentos que provocan la acción denotada por el verbo, ya sea de forma agencial o no, así como los que tradicionalmente se clasifican como experimentadores, es decir, los argumentos de verbos estativos como amor, odio, miedo. ARG1, por otro lado, son aquellos que cambian debido a una causalidad externa, así como otros tipos de argumentos \"afectados\"\n",
    "\n",
    "Los argumentos modificadores usados en PropBank son\n",
    "\n",
    "- DIR: Directionals\n",
    "- LOC: Locatives\n",
    "- MNR: Manner\n",
    "- EXT: Extent\n",
    "- REC: Reciprocals\n",
    "- PRD: Secondary Predication\n",
    "- PNC: Purpose\n",
    "- CAU: cause\n",
    "- DIS: discourse\n",
    "- ADV: adverbials\n",
    "- MOD: modals\n",
    "- NEG: negation\n",
    "- DSP: direct speech\n",
    "- RLC: relative clauses\n",
    "\n",
    "AllenNLP es capaz de reconocerlos y son etiquetados comenzando con el prefijo ARGM- facilitando su identificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a24a717-7bfc-4cca-ab72-43b1e40bb6fa",
   "metadata": {},
   "source": [
    "## Comentarios Finales sobre AllenNLP\n",
    "\n",
    "AllenNLP, es capaz de reconocer correctamente el FrameSet \"involucrado\" en la oración, y con la elección correcta de verbo, a los sujetos y objetos en la oración, siguiendo todas las reglas de PropBank. Además es capaz de etiquetar correctamente oraciones pasivas. Es importante recalcar que oraciones carentes de ARG0 o ARG1 no son necesariamente etiquetados incorrectos, pues pueden estár implícitos en la oración. Pueden incluso estar presentes en una frase etiquetas ARG1 y ARG2 sin la necesidad de un ARG0. Como ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fe346d-2e01-4956-ba2f-eef6fac3b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=\"John was hit by Mary\"\n",
    "output=allenslr.predict(sentence)\n",
    "print(\"\")\n",
    "print(\"Oración pasiva\")\n",
    "print(output['verbs'][1]['description'])\n",
    "sentence=\"John was hit\"\n",
    "output=allenslr.predict(sentence)\n",
    "print(\"\")\n",
    "print(\"Oración sin ARG0\")\n",
    "print(output['verbs'][1]['description'])\n",
    "sentence=\"Was acussed of conducting illegal business and possessinf illegal materials\"\n",
    "output=allenslr.predict(sentence)\n",
    "print(\"\")\n",
    "print(\"Oración con ARG2 únicamente\")\n",
    "print(output['verbs'][1]['description'])\n",
    "print(\"El acusado (ARG1) está implícito en 'was' y el acusador (ARG0) no está presente en la oración.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3188ae-189f-4044-b888-a7a5135694d0",
   "metadata": {},
   "source": [
    "## Algoritmo\n",
    "\n",
    "De todos los comentarios anteriores la tarea a lograr es identificar correctamente al verbo del listado que realiza AllenNLP. A partir de ahí, la creación de las tuplas (Sujeto, Objeto, Predicado) se realiza asumiendo que el etiquetado (la identificación de roles semánticos) de AllenNLP es correcto.\n",
    "\n",
    "**Proposición 1**: La creación de tuplas es posible si existen al menos dos etiquetas en la oración.\n",
    "\n",
    "La necesidad de este requerimiento es explicada si observamos que anotar únicamente al verbo nos deja sin posibilidades de distinguir sujetos, objetos y modificadores de entre todas las demás palabras al carecer de identificadores. Si existen al menos dos etiquetas, entonces es posible crear una tupla con al menos esas dos partes de la oración. Esto nos motiva a la siguiente definición\n",
    "\n",
    "**Definición 1**: Diremos que el etiquetado de una oración es valido si este contiene al menos dos etiquetas.\n",
    "\n",
    "Regresando a la salida de AllenNLP, el listado de posibles etiquetados depende de la _\"cantidad de verbos\"_  presentes en la oración. Ese listado puede ser de tamaño cero, es decir no ha reconocido ningún verbo, de tamaño uno, reconociendo un verbo únicamente o de tamañano mayor a uno.\n",
    "\n",
    "En el caso cero, no es posible crear ninguna tupla y el algoritmo debe lanzar una excepción.\n",
    "\n",
    "En el caso uno, el algoritmo debe verificar el etiquetado de la oración y si es válido, crear la tupla, de lo contrario lanzar una excepción.\n",
    "\n",
    "En el caso mayor a uno, el algoritmo debe verificar la validez del etiquetado. Funcionando como un primer filtro contra las anotaciones incorrectas de verbos.\n",
    "\n",
    "Una primera implementación en pseudocódigo:\n",
    "```\n",
    "function algorithm(sentence):\n",
    "    \n",
    "    output=AllenNLP(sentence)\n",
    "    n_verbs= call calculate_number_of_verbs(output)\n",
    "    \n",
    "    if(n_verbs == 0){\n",
    "        throw exception\n",
    "    }\n",
    "    \n",
    "    if(n_verbs == 1){\n",
    "        if(validate(output)){\n",
    "            create_tuple(output)\n",
    "        }\n",
    "        else{\n",
    "            throw exception\n",
    "        }   \n",
    "    }\n",
    "    \n",
    "    if (n_verbs >= 1){\n",
    "        for verbs in n_verbs{\n",
    "            validate(output(verb))\n",
    "        }\n",
    "    }\n",
    "```\n",
    "De tener más de un verbo anotado, seleccionaremos como la mejor anotación aquella que posea la menor cantidad de palabras sin etiquetar. Es decir el mejor verbo será aquel para el que exista una mayor cantidad de palabras etiquetadas como argumentos.\n",
    "\n",
    "Como nota, no es recomendable proponer un filtro que busque al mejor verbo anotado buscando la propuesta que tenga a absolutamente todas las palabras como argumentos, porque partimos del supuesto AllenNLP posee limitaciones en el etiquetado pudiendo omitir al menos alguna vez partículas, contracciones, modales y/o auxiliares.\n",
    "\n",
    "Con este método, podemos seleccionar la mejor anotación y crear la tupla necesaria, cubriendo todos los casos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d540f74",
   "metadata": {},
   "source": [
    "### La salida de AllenNLP:\n",
    "\n",
    "```python\n",
    "output['verb'] #es una lista de tamaño n con n verbos identificados. Cada elemento de la lista es un diccionario\n",
    "output['verb'][i] #es un diccionario. Tiene las claves\n",
    "{'verb': str,\n",
    " 'description': str\n",
    " 'tags': list\n",
    "}\n",
    "```\n",
    "Podemos usar `'tags'` para medir la cantidad de palabras que no pudieron ser etiquetadas y realizar las validaciones, pero es mejor realizar las extracciones a partir de la clave `'description'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a74cf49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def extract(sentence):\n",
    "    \"\"\"\n",
    "    from a sentence use AllenNLP SRLtool to extrac (subject-object, predicate) tuples\n",
    "    \n",
    "    Arguments\n",
    "        sentence :: str\n",
    "    \n",
    "    Returns:\n",
    "        If possible\n",
    "        (str, str) list \n",
    "        Else\n",
    "        None\n",
    "    \"\"\"\n",
    "    remove='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'\n",
    "    input=sentence.translate(str.maketrans('', '', remove))\n",
    "    count=[]                                        # num de palabras sin anotar por verbo\n",
    "    counter=0\n",
    "    output=allenslr.predict(input)\n",
    "\n",
    "    if len(output['verbs'])==0:                     # Ningun verbo anotado\n",
    "        print(\"ERROR: Ningún verbo anotado\")\n",
    "        return None\n",
    "    elif len(output['verbs'])==1:                   # Un verbo anotado\n",
    "        tags=output['verbs'][0]['tags']             # Valida el etiquetado\n",
    "        if bool(re.search('ARG[0-5]', string) for string in tags):\n",
    "            tuple=create_tuples(output)             # Extracción de información\n",
    "        else:\n",
    "            print(\"ERROR: Insuficientes etiquetas para crear la tupla\")\n",
    "            return None\n",
    "    else:                                           # Más de un verbo anotado\n",
    "        for verb in output['verbs']:                # Valida eitquetas para cada verbo\n",
    "            for tag in verb['tags']:\n",
    "                if tag == 'O':\n",
    "                    counter+=1                      # Cuenta las palabras sin anotar\n",
    "            count.append(counter)\n",
    "            counter=0\n",
    "        tags=output['verbs'][search(count)]['tags']\n",
    "        if bool(re.search('ARG[0-5]', string) for string in tags):\n",
    "            tuple=create_tuples(output, search(count))  # Extracción de información\n",
    "        else:\n",
    "            print(\"ERROR: Insuficientes etiquetas para crear la tupla\")\n",
    "            return None\n",
    "    return tuple\n",
    "def search(a):\n",
    "    \"\"\"\n",
    "    search algorithm to find the smallest amount of unlabel words\n",
    "\n",
    "    Args:\n",
    "    a :: list\n",
    "\n",
    "    Return\n",
    "    index of  the list :: int\n",
    "    \"\"\"\n",
    "    j=0\n",
    "    for i in range(1,len(a)):\n",
    "        if a[i]<a[j]:\n",
    "            j=i\n",
    "    return j\n",
    "def create_tuples(output, index=0):\n",
    "    \"\"\"\n",
    "    Create a tuple from PropBank Anotations\n",
    "\n",
    "    Arg:\n",
    "    output :: Dict create with AllenNLP SLR\n",
    "    index :: int to acces to the correct labeling \n",
    "    \n",
    "    Returns:\n",
    "    (sj_oj, prd) list\n",
    "    \"\"\"\n",
    "    SP=[]\n",
    "    O=[]\n",
    "    tags=output['verbs'][index]['tags']\n",
    "    words=output['words']\n",
    "    for a in range(0,5):\n",
    "        if any('ARG'+str(a) in string for string in tags):\n",
    "            for i in range(len(tags)):\n",
    "                if bool(re.search('ARG['+str(a+1)+'-5]', tags[i])):\n",
    "                    O.append(words[i])\n",
    "                elif not 'O' in tags[i]:\n",
    "                    SP.append(words[i])\n",
    "            break\n",
    "    SP=\" \".join(SP)\n",
    "    O=\" \".join(O)\n",
    "    return [SP,O]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b5bd23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ARGM-ADV: If you liked the music we were playing last night] , [ARG0: you] [ARGM-MOD: will] [ARGM-ADV: absolutely] [V: love] [ARG1: what we 're playing tomorrow] !\n",
      "['If', 'you', 'liked', 'the', 'music', 'we', 'were', 'playing', 'last', 'night', ',', 'you', 'will', 'absolutely', 'love', 'what', 'we', \"'re\", 'playing', 'tomorrow', '!']\n"
     ]
    }
   ],
   "source": [
    "sentence=\"If you liked the music we were playing last night, you will absolutely love what we're playing tomorrow!\"\n",
    "output=allenslr.predict(sentence)\n",
    "txt=output['verbs'][4]['description']\n",
    "print(txt)\n",
    "print(output['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c7c00934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['If you liked the music we were playing last night you absolutely love',\n",
       " \"what we 're playing tomorrow\"]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28611bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1=\"Diabetes is a noncommunicable disease\"\n",
    "sentence2=\"The cause of lung cancer can be DNA methylation\"\n",
    "sentence3=\"Cystic fibrosis is an example of an inherited disease that is caused by a mutation on a gene\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9fce2780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['More than a few CEOs say',\n",
       " 'the redcarpet treatment tempts them to return to a heartland city for future meetings']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence4=\"More than a few CEOs say the red-carpet treatment tempts them to return to a heartland city for future meetings.\"\n",
    "extract(sentence4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "2898ae7d1e065ed192af215b18819feb41424b0d642f4ae26747d5230ca4fd65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
